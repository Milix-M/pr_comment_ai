from os import getenv

import streamlit as st
from dotenv import load_dotenv
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain.memory import ConversationBufferWindowMemory
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI

from common.prompt import CUSTOM_SYSTEM_PROMPT
from tools.fetch import fetch_ddg_page
from tools.search import search_ddg

load_dotenv(verbose=True)


def init_page():
    # Streamlitãƒšãƒ¼ã‚¸ã®åŸºæœ¬è¨­å®š
    st.set_page_config(
        page_title="è‡ªå·±PRä½œæˆ Agent",  # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«
        page_icon="ğŸ¤—",  # ãƒšãƒ¼ã‚¸ã‚¢ã‚¤ã‚³ãƒ³
    )
    st.header("è‡ªå·±PRä½œæˆ Agent ğŸ¤—")  # ãƒ˜ãƒƒãƒ€ãƒ¼ã®è¨­å®š
    st.sidebar.title("Options")  # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¿ã‚¤ãƒˆãƒ«


def init_messages():
    # åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¨­å®šã¨ä¼šè©±ã®ã‚¯ãƒªã‚¢æ©Ÿèƒ½
    clear_button = st.sidebar.button(
        "Clear Conversation", key="clear"
    )  # ä¼šè©±ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãƒœã‚¿ãƒ³
    if clear_button or "messages" not in st.session_state:
        # ä¼šè©±ã‚’ã‚¯ãƒªã‚¢ã¾ãŸã¯åˆæœŸåŒ–
        st.session_state.messages = [
            {"role": "assistant", "content": "ã“ã‚“ã«ã¡ã¯ï¼ãªã‚“ã§ã‚‚è³ªå•ã‚’ã©ã†ãï¼"}
        ]
        st.session_state["memory"] = ConversationBufferWindowMemory(
            return_messages=True,  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™è¨­å®š
            memory_key="chat_history",  # ãƒ¡ãƒ¢ãƒªã‚­ãƒ¼ã®è¨­å®š
            k=10,  # ä¿æŒã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°
        )


def create_agent():
    tools = [search_ddg, fetch_ddg_page]  # ä½¿ç”¨ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆ
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", CUSTOM_SYSTEM_PROMPT),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )
    llm = ChatOpenAI(
        model="z-ai/glm-4.5-air:free",
        openai_api_key=getenv("OPENROUTER_API_KEY"),
        openai_api_base="https://openrouter.ai/api/v1",
    )
    agent = create_tool_calling_agent(llm, tools, prompt)
    return AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        memory=st.session_state["memory"],
        max_iterations=30,
    )


def main():
    init_page()
    init_messages()
    web_browsing_agent = create_agent()

    for msg in st.session_state["memory"].chat_memory.messages:
        st.chat_message(msg.type).write(msg.content)

    if prompt := st.chat_input(placeholder="LLMã¨ã¯ï¼Ÿ"):
        st.chat_message("user").write(prompt)

        with st.chat_message("assistant"):
            # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã®è¨­å®š (ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ä½œã®å¯è¦–åŒ–ç”¨)
            st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=True)

            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
            response = web_browsing_agent.invoke(
                {"input": prompt}, config=RunnableConfig({"callbacks": [st_cb]})
            )
            st.write(response["output"])


if __name__ == "__main__":
    main()
